# 爬虫的ip代理池

1. 爬取几个比较大的ip代理网站，抓取ip
2. 将抓取下来的ip进行验证
3. 将可用的ip保存到数据库里面


### todo
1. 验证代理可用是通过访问百度来实现的，需要等待一个timeout的时间，才能验证这个ip是否能用。这部分耗时太久，将代码改成多线程的运行方式，可以大大提高效率。
2. 支持更多的ip代理网站
3. 存在数据库里面的ip，需要现在能用，之后就不能用了，所以需要维护数据库里面ip的更新

### 如何使用
1. 第一次使用的时候，需要修改一下mysql的配置
2. 具体的使用方法 可以看demo.py 文件
3. demo.py 里面的main函数，是第一次进行爬取可用ip代理并保存到数据库
4. util.get() 随机获得一个可用的proxy
5. demo.py 里面的refresh() 用来更新数据库里面的ip代理


### 关于config文件
1. 支持开启的不同线程数
2. 支持添加新的代理网站（不过需要在配置文件里面补全抓取代理网站的xpath语法规则）3. clone到本地之后，需要修改数据库的配置

### other
运行环境 ubuntu 16.04 ，Python 3.5.2


### IP代理的来源
```
http://www.kuaidaili.com/free
http://www.xicidaili.com/nn/
```
